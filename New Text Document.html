<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Drowsiness Detector</title>
    <style>
        body { font-family: sans-serif; text-align: center; background: #222; color: white; }
        video { width: 100%; max-width: 600px; transform: scaleX(-1); border: 2px solid #555; }
        #status { font-size: 24px; margin: 10px; font-weight: bold; }
        .safe { color: #0f0; }
        .danger { color: #f00; background: yellow; padding: 10px; }
        button { padding: 10px 20px; font-size: 18px; cursor: pointer; background: #007bff; color: white; border: none; border-radius: 5px; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js" crossorigin="anonymous"></script>
</head>
<body>

    <h1>ðŸ˜´ Drowsiness Detector</h1>
    <div id="status" class="safe">Status: Waiting for Camera...</div>
    <video id="webcam" autoplay playsinline></video>
    <br>
    <button id="startBtn">Enable Camera & Start</button>

    <script type="module">
        import { FaceLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

        const video = document.getElementById("webcam");
        const statusDiv = document.getElementById("status");
        const startBtn = document.getElementById("startBtn");
        let faceLandmarker;
        let lastVideoTime = -1;
        let alarmCounter = 0;
        const EAR_THRESHOLD = 0.25;
        const FRAMES_TO_ALARM = 20; // Approx 1-2 seconds depending on FPS

        // 1. Setup MediaPipe Landmarker
        async function createLandmarker() {
            const filesetResolver = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                    delegate: "GPU"
                },
                outputFaceBlendshapes: true,
                runningMode: "VIDEO",
                numFaces: 1
            });
            statusDiv.innerText = "System Ready. Click Start.";
        }

        createLandmarker();

        // 2. Enable Webcam
        startBtn.addEventListener("click", async () => {
            if (!faceLandmarker) { alert("Please wait for model to load"); return; }
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.addEventListener("loadeddata", predictWebcam);
                startBtn.style.display = "none";
                statusDiv.innerText = "Status: Monitoring...";
            } catch (err) {
                alert("Camera access denied or not supported.");
            }
        });

        // 3. Main Detection Loop
        async function predictWebcam() {
            let startTimeMs = performance.now();
            if (lastVideoTime !== video.currentTime) {
                lastVideoTime = video.currentTime;
                
                // Detect faces
                const results = faceLandmarker.detectForVideo(video, startTimeMs);

                if (results.faceLandmarks.length > 0) {
                    const landmarks = results.faceLandmarks[0];
                    
                    // Calculate EAR for both eyes
                    // Left Eye Indices: 362, 385, 387, 263, 373, 380
                    // Right Eye Indices: 33, 160, 158, 133, 153, 144
                    const leftEAR = calculateEAR(landmarks, [362, 385, 387, 263, 373, 380]);
                    const rightEAR = calculateEAR(landmarks, [33, 160, 158, 133, 153, 144]);
                    
                    const avgEAR = (leftEAR + rightEAR) / 2;

                    // Check Drowsiness
                    if (avgEAR < EAR_THRESHOLD) {
                        alarmCounter++;
                        if (alarmCounter > FRAMES_TO_ALARM) {
                            statusDiv.innerText = "âš ï¸ WAKE UP! âš ï¸";
                            statusDiv.className = "danger";
                            // Optional: Play sound here
                        }
                    } else {
                        alarmCounter = 0;
                        statusDiv.innerText = "Status: Awake (EAR: " + avgEAR.toFixed(2) + ")";
                        statusDiv.className = "safe";
                    }
                }
            }
            window.requestAnimationFrame(predictWebcam);
        }

        // Helper Math Function
        function calculateEAR(landmarks, indices) {
            // Euclidean distance helper
            const dist = (i1, i2) => {
                const dx = landmarks[i1].x - landmarks[i2].x;
                const dy = landmarks[i1].y - landmarks[i2].y;
                return Math.sqrt(dx*dx + dy*dy);
            };
            
            // EAR Formula: (Vertical1 + Vertical2) / (2 * Horizontal)
            const A = dist(indices[1], indices[5]);
            const B = dist(indices[2], indices[4]);
            const C = dist(indices[0], indices[3]);
            return (A + B) / (2.0 * C);
        }
    </script>
</body>
</html>