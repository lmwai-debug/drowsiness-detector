<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modern Drowsiness Detector</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        /* --- MODERN CSS VARIABLES & RESET --- */
        :root {
            --bg-app: #0a0a0a;
            --bg-card: #1a1a1a;
            --text-primary: #ffffff;
            --text-secondary: #a0a0a0;
            --primary-color: #3b82f6;
            --success-color: #10b981;
            --danger-color: #ef4444;
            --card-radius: 16px;
        }

        body {
            font-family: 'Inter', sans-serif;
            background-color: var(--bg-app);
            color: var(--text-primary);
            margin: 0;
            padding: 20px;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            box-sizing: border-box;
        }

        .app-container {
            background-color: var(--bg-card);
            width: 100%;
            max-width: 700px;
            padding: 30px;
            border-radius: 24px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.4);
            text-align: center;
        }

        h1 {
            margin-top: 0;
            font-weight: 700;
            font-size: 1.8rem;
            margin-bottom: 25px;
        }

        .video-wrapper {
            width: 100%;
            border-radius: var(--card-radius);
            overflow: hidden;
            border: 3px solid #333;
            box-shadow: 0 8px 24px rgba(0,0,0,0.2);
            background: #000;
            margin-bottom: 25px;
        }

        video {
            width: 100%;
            display: block;
            transform: scaleX(-1); 
        }

        #status {
            padding: 20px;
            border-radius: var(--card-radius);
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 25px;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
        }

        .safe {
            background-color: rgba(16, 185, 129, 0.15);
            color: var(--success-color);
            border: 2px solid var(--success-color);
        }
        .safe::before { content: "üü¢"; font-size: 1.4rem; }

        .danger {
            background-color: rgba(239, 68, 68, 0.15);
            color: var(--danger-color);
            border: 2px solid var(--danger-color);
            animation: pulse 1.5s infinite;
        }
        .danger::before { content: "‚ö†Ô∏è"; font-size: 1.4rem; }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }

        button {
            padding: 14px 28px;
            font-family: 'Inter', sans-serif;
            font-size: 1rem;
            font-weight: 600;
            border: none;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.2s ease-in-out;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        #startBtn {
            background-color: var(--primary-color);
            color: white;
            box-shadow: 0 4px 12px rgba(59, 130, 246, 0.3);
        }
        #startBtn:hover { transform: translateY(-2px); background-color: #2563eb; }
       
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.4); }
            70% { box-shadow: 0 0 0 15px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js" crossorigin="anonymous"></script>
</head>
<body>

    <div class="app-container">
        <h1>ENGINEERING DRIVER DROWSINESS AI</h1>
        
        <div class="video-wrapper">
            <video id="webcam" autoplay playsinline></video>
        </div>

        <div id="status" class="safe">Waiting for Camera...</div>
        
        <div class="controls">
            <button id="startBtn">‚ñ∂ Start Monitor (Enable Audio)</button>
        </div>
    </div>

    <script type="module">
    import { FaceLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("webcam");
    const statusDiv = document.getElementById("status");
    const startBtn = document.getElementById("startBtn");
    let faceLandmarker;
    let lastVideoTime = -1;
    let alarmCounter = 0;
    let headDownCounter = 0;

    // --- AUDIO SETUP (Base64 Beep Sound) ---
    // This is a short synth beep encoded in Base64 so you don't need an external file.
    const beepBase64 = "data:audio/wav;base64,UklGRl9vT1BXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YU"; 
    // Note: The string above is cut short for brevity. I will use a generated Oscillator instead which is cleaner code.
    
    let audioCtx;
    let oscillator;
    let isBuzzing = false;

    function playAlarm() {
        if (isBuzzing) return; // Already playing
        
        // Create audio context if it doesn't exist
        if (!audioCtx) {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        }

        // Create oscillator (Sound generator)
        oscillator = audioCtx.createOscillator();
        const gainNode = audioCtx.createGain();

        oscillator.type = 'square'; // Harsh sound
        oscillator.frequency.setValueAtTime(650, audioCtx.currentTime); // 650Hz tone
        
        // Connect parts
        oscillator.connect(gainNode);
        gainNode.connect(audioCtx.destination);
        
        // Beeping pattern
        const now = audioCtx.currentTime;
        gainNode.gain.setValueAtTime(0.5, now);
        
        oscillator.start();
        isBuzzing = true;
    }

    function stopAlarm() {
        if (!isBuzzing) return;
        if (oscillator) {
            try {
                oscillator.stop();
                oscillator.disconnect();
            } catch(e) {} // Ignore errors if already stopped
        }
        isBuzzing = false;
    }


    // --- TUNED PARAMETERS ---
    const EAR_THRESHOLD = 0.18;     // Eyes closed threshold
    const EYE_FRAMES = 40;          

    // UPDATED: Sensitivity increased as requested
    const PITCH_THRESHOLD = 0.3;    // UPDATED from 0.65 to 0.3
    const HEAD_FRAMES = 30;         

    const ESP_IP = "192.168.4.1"; 

    async function sendSignal(endpoint) {
        const url = `http://${ESP_IP}/${endpoint}`;
        try {
            await fetch(url, { method: 'GET', mode: 'no-cors' });
        } catch (err) {}
    }

    // 1. Setup MediaPipe
    async function createLandmarker() {
        const filesetResolver = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
            baseOptions: {
                modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                delegate: "GPU"
            },
            outputFaceBlendshapes: true,
            runningMode: "VIDEO",
            numFaces: 1
        });
        statusDiv.innerText = "System Ready. Tap Start.";
    }

    createLandmarker();

    // 2. Enable Webcam & Audio Context
    startBtn.addEventListener("click", async () => {
        if (!faceLandmarker) { alert("Please wait for model to load"); return; }
        
        // Initialize Audio Context on user gesture to allow playback
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        
        try {
            const constraints = { video: { width: 640, height: 480, facingMode: 'user' } };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = stream;
            video.addEventListener("loadeddata", predictWebcam);
            startBtn.style.display = "none";
            statusDiv.innerText = "Initializing AI...";
        } catch (err) {
            alert("Camera access denied.");
            statusDiv.innerText = "Camera Error üö´";
            statusDiv.className = "danger";
        }
    });

    // 3. Main Detection Loop
    async function predictWebcam() {
        let startTimeMs = performance.now();
        if (lastVideoTime !== video.currentTime) {
            lastVideoTime = video.currentTime;
            
            const results = faceLandmarker.detectForVideo(video, startTimeMs);

            if (results.faceLandmarks.length > 0) {
                const landmarks = results.faceLandmarks[0];
                
                // Eye Tracking
                const leftEAR = calculateEAR(landmarks, [362, 385, 387, 263, 373, 380]);
                const rightEAR = calculateEAR(landmarks, [33, 160, 158, 133, 153, 144]);
                const avgEAR = (leftEAR + rightEAR) / 2;

                // Head Pose Tracking
                const nose = landmarks[1];
                const leftEyeOuter = landmarks[33];
                const rightEyeOuter = landmarks[263];
                
                const faceWidth = Math.sqrt(
                    Math.pow(rightEyeOuter.x - leftEyeOuter.x, 2) + 
                    Math.pow(rightEyeOuter.y - leftEyeOuter.y, 2)
                );
                const midEyeY = (leftEyeOuter.y + rightEyeOuter.y) / 2;
                
                const pitchRatio = (nose.y - midEyeY) / faceWidth;

                // --- LOGIC ---
                let isSleeping = false;
                let statusText = "";

                // Check Eyes
                if (avgEAR < EAR_THRESHOLD) {
                    alarmCounter++;
                } else {
                    alarmCounter = Math.max(0, alarmCounter - 1);
                }

                // Check Head
                if (pitchRatio > PITCH_THRESHOLD) {
                    headDownCounter++;
                } else {
                    headDownCounter = Math.max(0, headDownCounter - 1);
                }

                // Trigger Logic
                if (alarmCounter > EYE_FRAMES) {
                    isSleeping = true;
                    statusText = "WAKE UP! (Eyes Closed)";
                } else if (headDownCounter > HEAD_FRAMES) {
                    isSleeping = true;
                    statusText = "HEAD UP! (Distracted)";
                }

                // Update UI & Hardware
                if (isSleeping) {
                    statusDiv.innerText = statusText;
                    statusDiv.className = "danger";
                    sendSignal("alarm_on");
                    playAlarm(); // TRIGGER AUDIO
                } else {
                    statusDiv.innerText = `Active | EAR: ${avgEAR.toFixed(2)} | Pitch: ${pitchRatio.toFixed(2)}`;
                    statusDiv.className = "safe";
                    sendSignal("alarm_off");
                    stopAlarm(); // STOP AUDIO
                }
            }
        }
        window.requestAnimationFrame(predictWebcam);
    }

    function calculateEAR(landmarks, indices) {
        const dist = (i1, i2) => {
            const dx = landmarks[i1].x - landmarks[i2].x;
            const dy = landmarks[i1].y - landmarks[i2].y;
            return Math.sqrt(dx*dx + dy*dy);
        };
        const A = dist(indices[1], indices[5]);
        const B = dist(indices[2], indices[4]);
        const C = dist(indices[0], indices[3]);
        return (A + B) / (2.0 * C);
    }
    </script>
</body>
</html>